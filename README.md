Code corresponding to the paper "When and How to Fool Explainable Models (and Humans) with Adversarial Examples" by Jon Vadillo, Roberto Santana and Jose A. Lozano.

# Download the datasets and pretrained models
In order to reproduce our experiments:
### ILSVRC
- Download the Imagenet training set (ILSVRC2012) in *ilsvrc/datasets*.
- Download the Imagenet validation set (blurred) in *ilsvrc/datasets*.
### XRAY (COVID-Net)
- Download the [COVIDNet-CXR Small pretrained model](https://github.com/lindawangg/COVID-Net/blob/master/docs/models.md) in *xray/COVID-Net/pretrained*.
