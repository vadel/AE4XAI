Code corresponding to the paper "When and How to Fool Explainable Models (and Humans) with Adversarial Examples" by Jon Vadillo, Roberto Santana and Jose A. Lozano.

# Download the datasets and pretrained models
In order to reproduce our experiments:
### ILSVRC
- Download the (ILSVRC2012) Imagenet training set in *ilsvrc/datasets/*.
- Download the (blurred) Imagenet validation set in *ilsvrc/datasets/*.
### XRAY (COVID-Net)
- Download the [COVIDNet-CXR Small pretrained model](https://github.com/lindawangg/COVID-Net/blob/master/docs/models.md) in *xray/COVID-Net/pretrained/*.
